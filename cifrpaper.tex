\documentclass[authoryear]{elsarticle}
\usepackage{latexsym}
%\usepackage{rotate}
\usepackage{graphics}
%\usepackage{amsmath}
\usepackage{comment}
\bibliographystyle{chicago}



\newcommand{\logit}{\mathrm{logit}}
\newcommand{\I}{\mathrm{I}}
\newcommand{\E}{\mathrm{E}}
\newcommand{\p}{\mathrm{P}}
\newcommand{\e}{\mathrm{e}}
\newcommand{\vecm}{\mathrm{vec}}
\newcommand{\kp}{\otimes}
\newcommand{\diag}{\mathrm{diag}}
\newcommand{\cov}{\mathrm{cov}}
\newcommand{\eps}{\epsilon}
\newcommand{\ep}{\varepsilon}
\newcommand{\obdots}{\ddots}    % change this later
\newcommand{\Ex}{{\cal E}}
\newcommand{\rat}{{\frac{c_{ij}}{c_{i,j-1}}}}
\newcommand{\rmu}{m}
\newcommand{\rsig}{\nu}
\newcommand{\fd}{\mu}
\newcommand{\tr}{\mathrm{tr}}
\newcommand{\cor}{\mathrm{cor}}
\newcommand{\bx}[1]{\ensuremath{\overline{#1}|}}
\newcommand{\an}[1]{\ensuremath{a_{\bx{#1}}}}

\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}

\renewcommand{\i}{\item}
\newcommand{\sr}{\ensuremath{\mathrm{SRISK}}}
\newcommand{\cs}{\ensuremath{\mathrm{CS}}}
\newcommand{\cri}{\ensuremath{\mathrm{Crisis}}}
\newcommand{\var}{\ensuremath{\mathrm{VaR}}}
\newcommand{\covar}{\ensuremath{\mathrm{CoVaR}}}
\newcommand{\med}{\ensuremath{\mathrm{m}}}
\newcommand{\de}{\mathrm{d}}
\renewcommand{\v}{\ensuremath{\mathrm{v}_q}}
\newcommand{\m}{\ensuremath{\mathrm{m}}}
\newcommand{\tvar}{\ensuremath{\mathrm{TVaR}}}



\newcommand{\eref}[1]{(\ref{#1})}
\newcommand{\fref}[1]{Figure \ref{#1}}
\newcommand{\sref}[1]{\S\ref{#1}}
\newcommand{\tref}[1]{Table \ref{#1}}
\newcommand{\aref}[1]{Appendix \ref{#1}}




\newcommand{\cq}{\ , \qquad}
\renewcommand{\P}{\mathrm{P}}
\newcommand{\Q}{\mathrm{Q}}

\newcommand{\Vx}{{\cal V}}
\newcommand{\be}[1]{\begin{equation}\label{#1}}
\newcommand{\ee}{\end{equation}}





\begin{document}

% Title of paper
\title{Systemic risk and contagion effects in Australian financial institutions and sectors}
% List of authors, with corresponding author marked by asterisk
\author{Piet de Jong,  Geoff Loudon and Weihao Choo \\[4pt]
% Author addresses
\textit{Department of Applied Finance and Actuarial Studies\\ Macquarie University, Sydney, NSW 2109.}
\\[2pt]
%E-mail address for correspondence
{piet.dejong@mq.edu.au}}

% Running headers of paper:
\markboth%
% First field is the short list of authors
{De Jong}
% Second field is the short title of the paper
{Systemic risk}

\maketitle

\section{Literature review}

The starting point for the proposed research is the recent literature and the CIFR targeted areas and APRA aims and functions.
This recent literature includes the following
\cite{adrian2011covar},
\cite{acharya2012capital},
\cite{acharya2012measuring}
and \cite{brownlees2010volatility}.   The proposed research aims to extend and apply these techniques particularly in relation to the entities regulated by APRA.   Thus our  broad aim is to develop, implement and bring to bear recent developments in stress testing  on the aims of APRA and the CIFR targeted research areas detailed above.   

\section{Improved  measures of contagion and systematic risk}
\renewcommand{\c}{\ensuremath{\mathrm{CoVaR_q}}}
\renewcommand{\v}{\ensuremath{\mathrm{VaR}_q}}

$\covar_q$ as proposed in \cite{adrian2011covar} is a basis for proposed measures contagion, exposure and systemic risk.   It  suffers from a number of drawbacks:
\bi
\i Couched in terms of $\var_q$ containing the scale of the original measurements.   It is worthwhile to have measures and techniques robust to scale.
\i  Conditioning  on $\var_{0.5}$ is undesirable and relatively intractable.  In our proposal we reference stress with respect  to the unconditional $\var_q$.   This permits a more transparent analysis and estimation. 
\i  Our proposed approach  separates out scale effects and interdependence effects and aims to  relates these separately to external variables including shocks and drivers of systemic risk.   Thus $\var_q$ movements due to scale are disentangled from movements due to codependence with separate driver responses.
\ei

\section{Significance of the project and  policy implications}

Understanding the impact of external shocks and their propagation through   the financial system is vital for managing and remediating systemic risk. Effective regulation is dependent upon the development of a robust and reliable set of appropriate risk measures.  We propose new measures of systemic risk that relate marginal and joint distributions separately to external drivers. This allows for more cogent and coherent stress testing as it includes the estimation of contagion effects, exposure effects and systemic risk across related entities and different financial sectors. Improved stress testing, estimation of risk effects and transmission of shocks through the financial system will make for more cogent prudential policy, prudential margin setting and better identify sources of risk to the financial system.

\newcommand{\q}{\mathrm{Q}}
\section{Percentile sensitivity and contagion}\label{perc}

\subsection{Theorem}  Suppose $x$ is a random vector with marginal distributions\footnote{To economise on notation, write $F_j(x)\equiv F_j(x_j)\equiv F(x_j)$ and similar for other vector functions.} 
$$
F(x)\equiv \{F(x_1),\ldots ,F(x_p)\} \equiv (u_1,\ldots,u_p)\equiv u\ .
$$ 
Further suppose $0\le q\le 1$ is given and  $\q(x)$ is the vector of $q$--quantiles
$$
F\{\q(x)\}=q1=\q(u)\ ,
$$
where $1$ is a vector of $p$ ones. 
Define the stress vector with respect to $x_j$ as\footnote{In \cite{adrian2011covar}  $\Delta CoVar_q\equiv q_{y|x=q_x}-q_y$.  Variable $y$  is generally the ``financial system" and hence considered is the change in the \v\ of the system when institution $x$ stressed, with stress  interpreted as $x=q_x$.  On page 10 of their paper they incorrectly state ``... $CoVaR$ conditions on the event that [an] institution is at its VaR level, which occurs with probability $q$."} 
\be{stress}
\frac{\de\q(x)}{\de x_j} \equiv \q(x|u_j>q) - \q(x)\ ,
\ee
where $\q(x|u_j>q)$ is the vector of $q$--quantiles of $x$ given $u_j>q$.    Then if $\q(x)$  is linear in $q$ 
 then
\be{implicit}
\frac{\de\q(x_i)}{\de\q(x_j)} \equiv \frac{\de\q(x_i)/\de x_j}{\de\q(x_j)/\de x_j} =  
\frac{f_j}{f_i} 
 \frac{q_{ij}}{q(1-q)}\cq q_{ij}=C_{ij}(q+q_{ij},q) - q^2\ ,
\ee
where $f_i$ and $f_j$ are the densities of $x_i$ and $x_j$ evaluated at $\q(x_i)$ and $\q(x_j)$ and  $C_{ij}$ is the copula of $(u_i,u_j)$.   
Further if 
$$
s_{ij}\equiv \frac{q_{ij}}{q(1-q)}\ ,
$$ then  $-1\le s_{ij}\le 1$ with $s_{ij}=\pm 1$ if $x_i$ and $x_j$ are comonotonic and counter monotonic, respectively.  If $x_i$ and $x_j$ are independent then  $s_{ij}=0$. If $u_i$ and $u_j$ are exchangeable  then  $s_{ji}=s_{ij}$.

\subsection{Proof}

By definition
$$
\frac{\de\q(u_i)}{\de u_j} \equiv \q(u_i|u_j>q) -q \equiv q_{ij}\ ,
$$
where  $q_{ij}$ is such that
\be{Qdef}
q =  \frac{\P(u_i\le  q+q_{ij},u_j>q)}{1-q}  = \frac{ q+q_{ij}-C_{ij}(q+q_{ij},q)}{1-q}\ ,
\ee
Rearranging yields the second equation in \eref{implicit}.
Now
 \be{first}
 \frac{\de\q(x_i)}{\de x_j}\equiv \q_{q+q_{ij}}(x_i) - \q(x_i) \approx \q'(x_i)q_{ij}= \frac{q_{ij}}{f_i} \ ,
 \ee
where $'$ denotes differentiation with respect to $q$ and the subscript on $\q$ indicates the revised $q$ for the quantile calculation.  The approximation follows from a first order Taylor expansion and is exact if the quantile is linear in $q$.   Similarly
 \be{second}
 \frac{\de\q(x_j)}{\de x_j}\equiv  \q_{q+q(1-q)}(x_j) - \q(x_j)\approx \frac{q(1-q)}{f_j}\ .
 \ee
 Dividing \eref{first} by \eref{second} yields the first equation in  \eref{implicit} and completes the proof.

\subsection{Discussion}  The critical  result is that sensitivities factor into contributions from the ratios of the marginal densities and quantities calculated from the pairwise copulas.  The via  the implicit  equation for $q_{ij}$ in \eref{implicit}, solved using a  root finding algorithm.
  The quantities $q_{ij}$ are implicitly defined from the pairwise copulas. In summary the ``sensitivity" matrix 
$$
S \equiv \frac{\de Q(x)}{\de Q'(x)}\ ,
$$
where $'$ denotes transposition has ones on the diagonal quantities between $\pm 1$ off the diagonal.   The matrix $S$ is called the sensitivity matrix and displays the sensitivity of the $q$--quantile of  each component of $x$ to  stress in the same or other components.  

Since $f_i$ and $f_j$ are  the densities evaluated at $\q(x_i)$ and $\q(x_j)$  it follows that the ratio $f_i/f_j$ can be replaced by the ratio of the hazards.   This is  useful in cases were it is practical to model the hazard rather than the density.


\subsection{Implementation}

\fref{fig1} displays the empirical copulas calculated from four weekly closing stock prices labelled anz, cba, mcq and  wbc for $n=761$ weeks from 2000 April 12 through to 2014 October 29.  The empirical copulas are calculated by converting each observation to an empirical percentile and plotting the same against each of the other series percentiles.  

\begin{figure}
  \begin{center}
    \includegraphics{fig1.pdf}
    \caption{Pairwise copulas of bank stocks  cba, anz, mqg, wbc, and the overall bank index.  Red lines plot sensitivity $s_{ij}$ as a function of $q$.}\label{fig1}
   \end{center}
\end{figure}

To estimate  $q_{ij}$  at a particular $q$, the second equation in \eref{implicit} is iterated\footnote{The second equation in \eref{implicit} is a contraction mapping and hence has a fixed point.} starting from $q_{ij}=0$ where copulas are estimated as 
$$
\hat C_{ij}(u_i,u_j) \equiv \hat\E\{(p_{ik}\le u_i)(p_{jk}\le u_j)\}\ .
$$
Here $\hat\E$ computes the empirical mean over the cases $k=1,\ldots,n$ and $p_{ik}$ and $p_{jk}$ are the empirical percentiles  of case $k$ of $x_i$ and $x_j$, respectively.

\subsection{Generalisations}
\renewcommand{\r}{\mathrm{R}}
Similar results apply when $\Q(x)$ is replaced by  other risk measures such as $\r(x)\equiv\E\{xr(u)\}$ where $r$ is a given function which acts componentwise and $xr(u)$ denotes componentwise multiplication.  For example if $r(u)=mu^{m-1}$ then  $\r(x)=\E\{\max(x^1,\ldots,x^m)\}$ where  $x^1,\ldots,x^m$ are $m$ independent copies of $x$ and the risk measure is the expected worst outcome in $m$ independent trials.

With $\r(x)$, the analogue of \eref{stress} is 
\be{stress2}
\frac{\de\r(x)}{\de x_j} \equiv \r(x|u_j>r_j) - \r(x_j)\cq r_j\equiv\p\{x_j\le\r(x_j)\} \ .
\ee
This differs from \eref{stress}  in that a different risk measure is used and  $r_j$ replaces $q$.   If  the components of $\r(x)$ are linear in the $r_i$ then
\be{implicit2}
\frac{\de\r(x_i)}{\de\r(x_j)} =  
\frac{f_j}{f_i} 
 \frac{q_{ij}}{q(1-q)}\cq q_{ij}=C_{ij}(r_i+q_{ij},r_j) - r_ir_j\ ,
\ee
where $f_i$ and $f_j$ are the $x_i$ and $x_j$ densities at the $r_i$ and $r_i$ quantiles, respectively. 

\section{Conditionally Gaussian copulas}

Suppose $(u,v)=F_*(x,y)$  where $x$ and $y$ are scalar random variables.    Write  $t=1,\ldots,n$  where the $u_t$ are the ordered observed values of $u$ and $q_t=\Phi^-(u_t)$.  The correspondingly ordered values of $v$ and $z=\Phi^-(v)$ are denoted $v_t$ and $z_t$, $t=1,\ldots,n$.  Note $\Ex(z_t)=\Ex(q_t)=0$ and $\Vx(z_t)=\Vx(q_t)=1$ where $\Ex$ and $\Vx$ evaluate the mean and variance assuming $t$ is uniform on the integers $1,\ldots,n$. 

Smoothing methods are here proposed to smooth and simulate $y$ values  using a copula on $(u,v)$ constructed via    a cubic spline model linking $z$ and $u$.   Of particular concern are simulated $z$ when $u$ is  near $0$ or $1$ corresponding to  $x$ extremes.    Given a simulated $u$ and in turn $z$, $(x,y)=F^-_*\{u,\Phi(z)\}$, a draw from the joint.  Constraining $u$ draws to say the upper tail, yields corresponding upper tail values for $y$.   The challenge is to produce cogent $z$'s or $y$'s that properly reflect dependence in different parts of the distribution unencumbered by inappropriate constraints, and in particular tail constraints, inherent in say the Gaussian copula setup.    Practical methods admit fitting on the basis of observed data, and testing procedures for  departures or otherwise from Gaussianity.   The method outlined below achieves this.

\begin{comment}
   The simulation singles out independent and dependent variables.   Which should be which?  If $x$ and $y$ are actual time series the simulation $(x_t,\hat y_t)$ is ordered back into the original time series order.
\end{comment}

The conditionally Gaussian  (CG) copula model for $(u,v)$ is a model for $z_t\equiv \Phi^-(v_t)$ and $q_t\equiv\Phi^-(u_t)$, where $u_1 <\cdots<u_n$ is an ordered sample of $n$ independent uniform random variables with $v_t$, $t=1,\ldots,n$ correspondingly ordered and where it is assumed
\be{cusp}
z_t = \alpha_t+\beta q_t+ s\eps_t\cq \alpha_{t+1}=\alpha_t +\delta_t+1.268\eta_t\cq \delta_{t+1}=\delta_t+\eta_t\ ,
\ee
where $\eps_t$ and $\eta_t$ are zero mean disturbances with common variance $\sigma^2$.  The  $q_t$ term is the   Gaussian component,  $\alpha_t$ a nonparametric deviation, and $\eps_t$ noise.  
Then  $\E(\alpha_t|z_1,\ldots,z_n)$ interpolates the function $a(t)$ minimising
\be{spline}
 \sum_{t=1}^n \left[z_t-\{a(t)+\beta q_t\}\right]^2 + s^2\int_{-\infty}^{\infty} \left\{a''(t)\right\}^2\de t\ .
\ee
The minimum is $(s\sigma)^2$ and 
the minimising function $a(t)$ is a cubic spline -- piecewise twice differentiable --  passing closest, in the least squares sense, to $z_t-\beta q_t$ at the ``knots" $t=1,\ldots,n$ and subject to a constraint on the integral squared  of the second derivative $a''(t)$.  Smoothness increases with $s^2$ and in the limit $a(t)$ is a straight line $\alpha_0+\delta_0 t$. 

The $q_t$ move monotonically from near -3 to +3 with an average $\Ex(q_t)=0$ and variance $\Vx(q_t)=1$.   Similarly $z_t$ ranges between about $\pm 3$ with $\Ex(z_t)=0$ and $\Vx(z_t)=1$.   However the $z_t$ move imperfectly with $q_t$ depending on ...

The CG model is the usual Gaussian copula if $\alpha_t\equiv 0$.   The CGC is readily  fit to percentile data, and provides a practical platform for copula simulation.  Hence \eref{cusp} provides a flexible yet easily implemented and useable extension of the Gaussian copula.  Similar extensions  can be imposed on say student--$t$ quantiles as discussed in \sref{xx}.


The  parameters of \eref{cusp} are $s$, $\beta$,  $\sigma$ and starting conditions $\alpha_0$ and $\delta_0$.  Parameter $\delta_0$ often plays a minor  role and often appropriately set to zero.  The term $\alpha_t+\beta q_t$ is the signal and $\eps_t$, noise.    The signal is relatively smooth and contains Gaussian component $q_t$ if $\beta\ne 0$.   Departures of $z_t$ from the Gaussian component  are the sum of a persistent component $\alpha_t$ and  transient component, $s\eps_t$.  Since  $\eps_t$ and  the driver of persistence $\eta_t$  share $\sigma$, the smoothing parameter $s$ measures relative importance of transience as opposed to persistence.   The scale parameter $\sigma$ relates to the degree of roughness since it is the variance of the changes in the local slope of $\alpha_t$.


Model \eref{cusp} provides an analysis of variance  type decomposition for $z_t$:
\be{anova}
 1= \Vx(\alpha_t) + \beta^2 + (s\sigma)^2\ ,
\ee
holding since $\Vx(z_t)=\Vx(q_t)=1$ and the fact $\eps_t$ and $\eta_t$ are uncorrelated.
Decomposition \eref{anova} splits the total variance  $\Vx(z_t)=1$ into that due to the nonparametric component $\alpha_t$,  Gaussian component $\beta^2$ and residual noise, $(s\sigma)^2$.  Alternatively \eref{anova} states the variance of the nonparametric component is $1-\beta^2-(s\sigma)^2$.

The \ Gaussian correlation is the partial correlation between $z_t$ and the Gaussian component $q_t$,  after removing the nonparametric component $\alpha_t$: 
\be{rho}
\rho_G\equiv\cor(z_t-\alpha_t,q_t)  = \frac{\beta}{\sqrt{\beta^2+(s\sigma)^2}}=\pm\left\{1+\left(\frac{s\sigma}{\beta}\right)^2\right\}^{-1/2}\ ,
\ee
where the sign is that of $\beta$.  Hence $\rho_G=1$ or 0 according to whether  $s\sigma=0$ or $\beta=0$, respectively.
Using \eref{anova},  $\rho_G^2$ equals the proportion of  residual variance $\Vx(z_t)-\Vx(\alpha_t)=\beta^2+(s\sigma)^2$ explained by  the Gaussian component $q_t$. 
 
Similarly the nonparametric correlation is the correlation between $z_t$ and the nonparametric component $\alpha_t$ after removing the Gaussian component:
\be{rho2}
\rho_N\equiv\cor(z_t-\beta q_t,\alpha_t) = \left\{1-\frac{(s\sigma)^2}{1-\beta^2}\right\}^{1/2}=\left\{\frac{\beta^2/(1-\beta^2)}{\rho_G^2/(1-\rho_G^2)}\right\}^{1/2}\ ,
\ee
\begin{comment}
$$
= \cor(\alpha_t+s\eps_t,\alpha_t) =\frac{1-\beta^2-(s\sigma)^2}{\sqrt{(1-\beta^2-(s\sigma)^2)(1-\beta^2)}}= \left\{\frac{1-\beta^2-(s\sigma)^2}{1-\beta^2}\right\}^{1/2} 
$$
\end{comment}
and  $\rho_N$ is 1 or 0 according to whether  $s\sigma$ equals 0 or  $\sqrt{1-\beta^2}$, respectively. 
\begin{comment}
$$
\cov(z_t-\alpha_t) = \cov(\beta q_t+s\eps_t) = \beta^2 +s^2\sigma^2\ .
$$
\end{comment}
Finally the overall correlation is the correlation between $z_t$ and the signal, consisting of both nonparametric and Gaussian component:
$$
\rho\equiv\cor (z_t,\alpha_t+\beta q_t)=\cor(z_t,z_t-s\eps_t)=\frac{1-(s\sigma)^2}{\sqrt{\cov(z_t-s\eps_t)}}=\sqrt{1-(s\sigma)^2}\ .
$$
with $\rho=\rho_N$ if $\beta=0$.   If $s=0$, there is no measurement error in \eref{cusp} or, equivalently, there is no roughness penalty in \eref{spline} and $\rho_G=\rho_N=\rho=1$.

\begin{comment}
reducing to \eref{rho} except that $s$ is replaced by
$$
v\equiv \Ex\left(\sum_{j=1}^{t-1}w_j^2\right) = xxx \cq \alpha_t=\sum_{j=1}^{t-1} w_j\eta_{t-j}
$$
The derivation of $v=xxx$ is shown  appendix.  Equivalently $\rho_v^{2}$ is the proportion of $\Vx(z_t)$ explained by the nonparametric and Gaussian component.


From \eref{rho} 
\be{OR}
\left(\frac{v}{s}\right)^2=\frac{\rho_s^2/(1-\rho^2_s)}{\rho_v^2/(1-\rho_v^2)} \equiv \mathrm{OR} \ ,
\ee
the odds ratio of local to global correlation.  In general $v>s$ implying $\mathrm{OR}>xx$.   

\end{comment} 

\begin{comment} 
$$
\rho = \cor(z_t,q_t) =\frac{\beta}{\sqrt{\beta^2+\cov(\alpha_t)}}=\pm\left\{1+\left(\frac{v\sigma}{\beta}\right)^2\right\}^{-1/2}\ .
$$
The expressions follow from a detailed calculation
$$
\cov(z_t,q_t) = \E\{(\alpha_t+\beta q_t)q_t\} = \beta
\cq
\cov(z_t) =\cov(\alpha_t)+\beta^2\cq \cov(q_t)=1
$$
where .   A detailed calculation shows
\end{comment}

\tref{pp} sets out possible choices for $s$ and $\beta$.   These combinations are discussed in the further subsections.  Note that $s=0$ does not imply $s\sigma=0$ as $s\rightarrow 0$ may imply $s\sigma$ converges to a positive number.

\begin{table}[htdp]
\caption{Special cases of the conditionally Gaussian copula}\label{pp}
\begin{center}
\begin{tabular}{l|cccccc}
\hline
model&$s$& $\alpha_0$&$\beta$&OR\\
\hline
empirical & 0 &  & &$\infty$ &\\
conormal & $>0$ & & $\pm 1$\\
conditionally Gaussian & $>0$ & & $\ne 0$ & $>1$ \\
linear probit & $\infty$ &  &0\\
Gaussian & $\infty$& 0\\
independence &  $\infty$& 0&0\\
co/counter monotonic & $\infty$ &0 &$\pm 1$ \\
\hline
\end{tabular}
\end{center}
\end{table}%

\subsection{Empirical copula}

The empirical copula results in \eref{cusp} when $s=0$.  In this case   $z_t=\alpha_t+\beta q_t$.    The deviation of $z_t-(\alpha_t+\beta q_t)$ can be made zero by selecting appropriate $\eta_t$.  Hence $s=0$ implies the fitted copula is the empirical copula.  Note $\Ex(\alpha_t)=0$ and $1=\Vx(z_t)=\Vx(\alpha_t)+\beta^2$.

\subsection{Large local variation}

The other  extreme  $s\rightarrow\infty$ is displayed  bottom rows of \tref{pp}.  Large $s$ forces negligible $\sigma$  and straight line behaviour for $\alpha_t$ yielding
$$
z_t= \alpha_0+\delta_0 t + \beta q_t + s\eps_t\cq t=1,\ldots, n\ ,
$$
where $s\eps_t$ has finite variance $(s\sigma)^2$.    Since $\Ex(q_t)=\Ex(z_t)=0$ any fitted relation is such that
$$
\delta_0=\frac{-2\alpha_0}{n+1}\cq z_t=  \alpha_0(1-2u_t)+\beta q_t + s\eps_t \ .
$$
Additionally $\Vx(q_t)=\Vx(z_t)=1$ implying
\be{constraint}
 1= \frac{\alpha_0^2}{3}-2\alpha_0\beta c+\beta^2+(s\sigma)^2\cq c\equiv\cov(u_t,q_t)\approx 2.82\ ,
\ee
and hence at most two of $\alpha_0$, $\beta$ and $s\sigma$ can be chosen freely.  

\subsubsection{Gaussian copula}
If $s\rightarrow\infty$ and  $\alpha_0=0$ then $(q_t,z_t)$ is bivariate   Gaussian with unit variances and correlation $\beta$ and \eref{cusp} reduces to a Gaussian copula with correlation $\beta$ and the odds ration \eref{OR} is 1, that is local and ordinary correlation coincide and \eref{constraint} reduces to $\beta=\pm\sqrt{1-(s\sigma)^2}$. 

\subsubsection{Probit copula}


 If $s\rightarrow\infty$ and  $\beta=0$ then \eref{cusp} defines a probit copula.   From \eref{constraint}, $\alpha_0=\pm\sqrt{ 3\{1-(s\sigma)^2\}}$. 
 
 \subsubsection{Independence}
 If $s\rightarrow\infty$ and  $\alpha_0=\beta=0$ then the variables are independence.   The situation is achieved either letting $\beta\rightarrow 0$ with a Gaussian copula or letting $\alpha_0\rightarrow 0$ with a Probit copula.  Under independence $s\sigma=1$.  
 
 \subsection{Conditionally Gaussian copula}  

This is the intermediate situation where  $0<s<\infty$.  Testing $\alpha_0=1/s=0$ is a test for a Gaussian copula.   Goodness of fit is measured with 
\be{R2}
\hat\rho^2= 1-(s\hat\sigma)^2=1-\Ex\{(z_t-\hat z_t)^2\}\ ,
\ee
where  $\hat z_t$ is the estimate of $z_t$ based on \eref{cusp} using estimates of $\alpha_0$, $\delta_0$, $\beta$ and $s\sigma$.  
Values of $\hat\rho^2$ lie between 0 and 1 and have the usual interpretation:    near 1 indicates the percentiles of $u$ well explain $z$ values of $v$.   
Note $R\rightarrow\beta$  if $\alpha_0=0$ and $s\rightarrow \infty$.

From \eref{R2}
$$
\Ex\left\{ \left(\frac{z_{t}-\hat z_{t}}{s\hat\sigma}\right)^2\right\}=1
$$
suggesting  the comparison of standardised residuals  to $\pm 2$ and perhaps plotting the percentile rank of the standardised residuals against $u_t$ to identify  lack of fit.  Note $R^2$ differs from the correlation coefficient $\beta$ since.
$$
\frac{R}{\beta}=\pm \sqrt{1-(s\hat\sigma)^2}\left\{1+\left(\frac{s\sigma}{\beta}\right)^2\right\}
$$
This emphasises the difference between $R^2$ and $\beta$.   The former measures the goodness of fit of a semiparametric function of $u$ to explain $z$ while $\beta$ measures the ability of a straight line in $q$ to explain $z$.  If $\beta\ne 0$ then $q$ forms part of the semiparametric specification and hence if $\beta\ne 0$,  $R^2>\beta^2$.  

   The implied correlation between $z_t$ and $q_t$ is  
$$
\beta=\frac{\beta}{\sqrt{\beta^2+(s\sigma)^2}} = \pm\left\{1+\left(\frac{s\sigma}{\beta}\right)^2\right\}^{-1/2}\ .
$$
The term $\beta/(s\sigma)$ is the signal to noise ratio.  If $z_t, q_t\sim (0,1)$ then $\beta^2+(s\sigma)^2=1$ and  
$$
\beta=\pm\sqrt{1-(s\sigma)^2}=R=\beta \cq \frac{\beta}{s\sigma} = \frac{\pm\sqrt{1-(s\sigma)^2}}{s\sigma} = \frac{\beta}{\sqrt{1-\beta^2}} 
$$.


 Thus the empirical correlation between $z_t$ and $q_t$ is
$$
\sum_{t=1}^n z_tq_t = \beta+\delta_0\sum_{t=1}^n tq_t 
$$




By construction both $z_t$ and $q_t$ have mean zero and variance 1 implying
the correlation between $z_t$ and $q_t$ is


If  $\beta=0$ then 
$$
z_t=\alpha_0 + n\delta_0 u_t+\beta \Phi^-(u_t) +s\eps_t\ ,
$$
    Testing $\delta_0=0$ amounts to testing for independence.  If $\beta=\pm 1$ then 
$z_t-(\pm q_t)=\alpha_0+t\delta_0$ implying $\alpha_0=n\delta_0=0$ and  $z_t=\pm q_t$, that is the variables are co or counter monotonic.   Finally if $\beta\ne 0,\pm 1$ then $z_t=\alpha_0+t\delta_0+\beta q_t+s\eps_t$  since  $\alpha_0=\delta_0=0$, implied by the fact that    Since both $z_t$ and $q_t$ are, by construction, standard normal, this  amounts to prescribing  a Gaussian copula with correlation indicated in \tref{pp}.
The ratio $\beta/(s\sigma)$ is the  signal to noise ratio.

The middle column of the body of \tref{pp} displays alternatives for finite $s\ne 0$.   If $\beta=0$  the implied copula is nonparametric with $\alpha_t$ evolving smoothly as a function of $t$ with the actual degree of smoothness increasing with $s$.  A constraint is $\alpha_0=\alpha_n=\sum_t\delta_t=0$ and hence $\alpha_t$ forms a bridge.  If $\beta=\pm 1$ then the signed difference $z_t-(\pm q_t)$ is modelled as a smooth. In a fit, the  bridge structure is expected to be enforced by the data.

The scale  $\sigma$ quantifies roughness in the signal $\alpha_t$ but its size is determined by $s$ with $s\sigma\le 1$ implied by the standard normality of $z_t$.   
In fitting, $s$ is either chosen a--priori, or estimated together with the other parameters. Given $s$, estimates of  $\beta$, $\alpha_0$, $\delta_0$ and $\sigma$ are closed form generalised least squares calculations.    Thus $s$ can be estimated  using a one dimensional search.   Given the values of the parameters,  standard diagnostics are used to assess the fit and reveal areas of inadequate fit.  These techniques are used and explained in the applications.



Use of $q_t$ permits  a partially Gaussian explanation of the copula with  Gaussianity increasing with $s$.   In the limit the enforced Gaussian copula has correlation $R$ signed according to $\hat\beta$.  Co or  countermonotoniticity implies $R=\pm 1$ with the sign indicating the direction of the relationship.  Setting $\beta=0$  excludes the Gaussian copula  component.



\begin{table}[htdp]
\caption{Predicted $z_t$ with conormal copula model}\label{ppp}
\begin{center}
\begin{tabular}{c||c|c|c}
\hline
&$s=0$& $0<s<\infty$ &$s\rightarrow\infty$\\
\hline\hline
$\beta=0$&& $\alpha_t$&$\alpha_0(1-2u_t)$ \\
& & non parametric& linear probit\\
& & probit & independence: $\alpha_0=0$ \\
\cline{1-1}\cline{3-4}
$\beta\ne 0,\pm 1$  & $z_t$ & $\alpha_t+\beta q_t$ &$\alpha_0(1-2u_t)+\beta q_t$\\
&empirical & conormal & Gaussian if $\alpha_0=0$\\
\cline{1-1}\cline{3-4}
$\beta=\pm 1$& & $\alpha_t\pm q_t$& $\alpha_0(1-2u_t)\pm q_t$ \\
& & cointegrated & co/counter monotonic \\
& & departure & if $\alpha_0=0$ \\
\hline
\end{tabular}
\end{center}
\end{table}%


The fitted values $\hat z_t$ stacked in  vector $\hat z$  provide a basis for simulating all percentiles including extreme percentiles.   In particular suppose $z\sim N(\hat z, \Sigma)$ where $\Sigma$ is the covariance matrix implied by the model.   Then $v\sim\Phi_*(z)$ is a simulation of the the $v_t$.   Bringing $v$ into the original order yields $(u_t,v_t)$, a simulation from the copula.  Simulated percentiles are  mapped back into the original scale as   $F_*^-(u_t,v_t)$ to provide simulated $(x_t,y_t)$ outcomes.  

\section{Copula forcing}

Even if data suggests a strict Gaussian copula it  may be desirable to force stronger dependence, especially in the tails. This forcing is achieved with 

\section{Application to copula fitting}

The following example illustrates the copula fitting technique.




\section{Financial sensitivity and contagion}
 

Suppose the singular value decomposition of the  matrix $S$ of sensitivities at a particular $q$ is 
$S= UDV'$.  Here  $D$ a diagonal matrix of singular values, arranged in decreasing order along the diagonal and $U$ and $V$ are orthonormal:  $U'U=V'V=I$.  If the series are independent then $U=D=V=I$.   If the series are comonotonic then $U=V=(1,0)$ while $D=\diag(1,0,\ldots,0)$.  Hence in the comonotonic case $S=11'$.

So the best thing is to compare 
$$
Q= s_{i1}c_{j1} + \cdots + s_{ip}c_{jp} 
$$

If $Q=I$ then $S=C=I$.   If $Q=11'$, a matrix of ones, then $S=\sqrt{p}(1,0)$ and $C=(c,0)$ both have rank 1:  here $s$ and $c$ are the leading columns of $S$ and $C$, respectively and 0 a matrix of zeros.

The approximation $Q\approx sc'$ is exact if $Q$ has rank 1 implying $Q=11'$.   The approximation $Q\approx sc'$ is inadequate if $Q=I$.  Inadequacy can be judged from the largest singular value in $D$, as a proportion of $p$, the number of variables or rows in $Q$.

$$
Q_* \equiv \frac{1}{p-1}(Q-I)=UDV'\cq s\equiv Q_*1\cq c\equiv Q_*'1\ .
$$$$
Q=I + s1'+ UDV'\cq s\equiv \frac{1}{p-1}(Q-I)1
$$
Then $s$ is the vector of average \v\ sensitivity of each variable to all others.  Further $c$ is the average \v\ impact of each variable on all others.   The matrices $U$, $D$ and $V$ define the singular value (svd) decomposition of $Q_*$, arranged so that diagonal matrix $D$ has the singular values on  the diagonal in descending order.   If $b=d_1u_1$ and $c=v_1$ where $u_1$, $d_1$ and $v_1$ are the first column, top diagonal entry, and first column of $U$, $D$ and $V$ respectively, then  for two variables $y\ne x$ in $Q$,
$$
\Delta_x q_y = s_y+ b_yc_x +\eps_{yx}
$$
This states that percentage sensitivities are, apart from the ``error" $\eps_{yx}$, an average sensitivity plus a scaled response to the contagious effect of the $x$ variable.   The contagious effects contained in $c$ are estimated by maximising the explanation of $Q$.


The vector $1'Q$ sums  the changes in \v\ when each of the column variables is stressed, and writes this as a proportion of the change in the variable being stressed.   These proportional sums, subtracting 1 and divided by  $p-1$ where $p$ is the number of variables, measures the average contagion of each variable on all others:  $c'=(p-1)^{-1}1'(Q-I)$ or $c=(p-1)^{-1}(Q-I)'1$

Alternatively the vector $Q1$ sums the changes in \v\ of each row variable when all the column variables are stressed.   Again it is appropriate to remove the effect of a variable on itself and consider the average over the remaining variables:  $s\equiv(p-1)^{-1}(Q-I)1$.  If $Q_*\equiv (p-1)^{-1}(Q-I)$ then $s=Q_*1$ and $c=\dot q_*1$ are the vectors of sensitivities and contagions, respectively.  If $Q=I$ then $s=c=0$.   If $Q=11'$ then $s=c=1$.



 
 \section{Systemic risk and causal chains}
A rank one approximation to the matrix  $Q$ is 
 $
 Q  \approx  sc' 
 $.
 Vector $c$ is an index of the contagious  impact of each of variables on the others while $s$ measures the sensitivity of each variable to each of the others.  The vectors $s$ and $c$ are derived from the singular value decomposition $Q=UDV'$ where $U'U=V'V=1$  and  where $s$ and $c$ are the first column of $UD$ and $V$  respectively, assuming the svd is organised so that the singular values in the diagonal matrix $D$ are organised from largest to smallest.   The appropriateness of the summarisation $sc'$ is measured with $\tr(Q-sc')$.
 
If the variables are independent then $Q=I$ and both $s$ and $c$ equal a column of the identity matrix with $sc'$ a matrix of 0's except in a single diagonal position where it is 1.   Then all but one variable has a contagion effect and only that variable is sensitive to the contagion provided by the  variable.

If the variables are comonotonic then $Q=11'$ and $s=1$ and $c=1$ where 1 denotes a vector of ones.   Thus the rank 1 approximation is exact and each variable is equally contagious and equally sensitive.
 
 Note that 
 $$
 Q^{n} \approx (s'c)^{n-1}sc'=\ ,
 $$
 
 
 If the random variables are independent the $Q-I=0$ and $a=b=k=0$ and there is no error in the first order svd approximation.    If the random variables are comonotonic then $Q=11'$ and $Q-I$ has ones everywhere except on the diagonal where it is zero.   The vector of row means is then $p^{-1}(p-1)1$
 
Systemic risk in the system is measured with $b'k=d_1(u_1'v_1)$.   In the case of comonotonic  random variables $Q=11'$, $a=1$ and $x$, where $p$ is the number of variables,  $d_1=1$. 
 
Furthermore we may define quantities such as
$
u^- \equiv \var_q(v|u\le q)
$
measuring the impact of a non distressed state in $v$.  For brevity we do not dwell on these constructs in this writeup although the ramifications and potential uses of these constructs will be  investigated in the research.

\section{Generalising Sklar's Theorem}

Skalr's Theorem states that if $F(x)$ is a a joint then there exists a $C$ such that
$
F=C\circ F_*
$ where $C_F=F$
\section{Literature}

We propose a measure for systemic risk: CoVaR, the value at risk (VaR) of financial institutions conditional on other institutions being in distress. We define an institution?s (marginal) contribution to systemic risk as the difference between CoVaR and the financial system?s VaR. From our estimates of CoVaR for characteristic-sorted portfolios of publicly traded financial institutions, we quantify the extent to which characteristics such as leverage, size, and maturity mismatch predict systemic risk contribution. We argue for macro-prudential regulation based on the degree to which such characteristics forecast systemic risk contribution.

\section{Econometric implementation}

The above development sets out our proposed  broad  framework for linking bivariate copulas and marginals to external variables and shocks study the impact of the same on stresses within the system and the contagious effects of crises.   Proposed econometric analysis will implement and extend  \cite{brownlees2010volatility}.

\section{Data}

We will employ publicly available data as published by APRA and other regulators.

\section*{References}
\bibliography{piet2}


\end{document}
